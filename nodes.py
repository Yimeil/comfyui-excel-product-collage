# ComfyUI/custom_nodes/excel_sku_collage/nodes.py

import pandas as pd
import requests
from PIL import Image
from io import BytesIO
import numpy as np
import torch
from collections import defaultdict, OrderedDict
import os
import warnings
import folder_paths

warnings.filterwarnings('ignore', message='Unverified HTTPS request')

def is_url(path):
    """æ£€æµ‹æ˜¯å¦ä¸º HTTP/HTTPS URL"""
    if not path:
        return False
    path_lower = path.strip().lower()
    return path_lower.startswith('http://') or path_lower.startswith('https://')

# æ³¨å†ŒExcelæ–‡ä»¶å¤¹
excel_folder = os.path.join(folder_paths.get_input_directory(), "excel_files")
if not os.path.exists(excel_folder):
    os.makedirs(excel_folder)
folder_paths.add_model_folder_path("excel_files", excel_folder)

class ExcelSKULoader:
    """
    Excel SKUæ•°æ®åŠ è½½å™¨
    è¯»å–Excelä¸­çš„SKUåˆ†ç»„ä¿¡æ¯ï¼Œä¸‹è½½å›¾ç‰‡å¹¶ç”Ÿæˆæ ‡ç­¾
    æŒ‰ç»„åˆSKUåˆ†æ‰¹è¾“å‡ºï¼Œæ¯ä¸ªç»„åˆSKUç”Ÿæˆä¸€ä¸ªæ‰¹æ¬¡
    """
    
    _image_cache = {}
    _cache_max_size = 100
    _cache_hits = 0
    _cache_misses = 0
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "excel_file": ("STRING", {
                    "default": "",
                    "multiline": False,
                    "placeholder": "æ”¯æŒæœ¬åœ°è·¯å¾„æˆ–URLï¼ˆå¦‚ï¼šfile.xlsx æˆ– https://example.com/file.xlsxï¼‰"
                }),
                "sheet_name": ("STRING", {
                    "default": "Sheet1",
                    "placeholder": "å·¥ä½œè¡¨åç§°"
                }),
                "combined_sku_col": ("STRING", {
                    "default": "A",
                    "placeholder": "ç»„åˆSKUåˆ—"
                }),
                "sku_col": ("STRING", {
                    "default": "B",
                    "placeholder": "SKUåˆ—"
                }),
                "pcs_col": ("STRING", {
                    "default": "C",
                    "placeholder": "PCSæ•°åˆ—"
                }),
                "url_col": ("STRING", {
                    "default": "D",
                    "placeholder": "å›¾ç‰‡URLåˆ—"
                }),
                "start_row": ("INT", {
                    "default": 2,
                    "min": 1,
                    "max": 10000,
                    "step": 1
                }),
                "use_cache": ("BOOLEAN", {
                    "default": True,
                    "label_on": "å¯ç”¨ç¼“å­˜",
                    "label_off": "ç¦ç”¨ç¼“å­˜"
                }),
                "cache_size": ("INT", {
                    "default": 100,
                    "min": 10,
                    "max": 1000,
                    "step": 10
                }),
                "label_format": (["Ã—{pcs}", "x{pcs}", "{pcs}ä»¶", "{pcs}å¥—", "PCS:{pcs}"], {
                    "default": "Ã—{pcs}"
                }),
                "output_mode": (["all_in_one", "by_combined_sku"], {
                    "default": "by_combined_sku"
                }),
            },
            "optional": {
                "filter_combined_sku": ("STRING", {
                    "default": "",
                    "multiline": False,
                    "placeholder": "ç•™ç©ºå¤„ç†å…¨éƒ¨ï¼Œæˆ–è¾“å…¥ç‰¹å®šç»„åˆSKU"
                }),
            }
        }
    
    RETURN_TYPES = ("IMAGE", "STRING", "STRING")
    RETURN_NAMES = ("images", "labels", "combined_sku_info")
    FUNCTION = "load_sku_data"
    CATEGORY = "ğŸ¨ Smart Collage/Excel"
    OUTPUT_NODE = False
    OUTPUT_IS_LIST = (True, True, False)  # imageså’Œlabelsè¾“å‡ºä¸ºåˆ—è¡¨

    @classmethod
    def IS_CHANGED(cls, excel_file, **kwargs):
        # URL æ¯æ¬¡éƒ½é‡æ–°åŠ è½½
        if is_url(excel_file):
            return float("nan")

        # æ£€æŸ¥æ–‡ä»¶ä¿®æ”¹æ—¶é—´
        file_path = os.path.join(excel_folder, excel_file)
        if os.path.exists(file_path):
            return os.path.getmtime(file_path)
        return float("nan")

    @classmethod
    def VALIDATE_INPUTS(cls, excel_file, **kwargs):
        # éªŒè¯æ–‡ä»¶è·¯å¾„
        if not excel_file or not excel_file.strip():
            return "è¯·è¾“å…¥Excelæ–‡ä»¶è·¯å¾„æˆ–URL"

        file_path = excel_file.strip()

        # å¦‚æœæ˜¯ URLï¼Œåªæ£€æŸ¥æ ¼å¼
        if is_url(file_path):
            # æ£€æŸ¥ URL æ˜¯å¦ä»¥ Excel æ‰©å±•åç»“å°¾ï¼ˆå¯é€‰ï¼Œå› ä¸ºæœ‰äº› URL å¯èƒ½æ²¡æœ‰æ‰©å±•åï¼‰
            # è¿™é‡ŒåªåšåŸºæœ¬éªŒè¯ï¼Œå®é™…ä¸‹è½½æ—¶ä¼šè¿›ä¸€æ­¥æ£€æŸ¥
            return True

        # åˆ¤æ–­æ˜¯å®Œæ•´è·¯å¾„è¿˜æ˜¯æ–‡ä»¶å
        if not ('\\' in file_path or '/' in file_path or ':' in file_path):
            # åªæ˜¯æ–‡ä»¶åï¼Œä» excel_files æ–‡ä»¶å¤¹æŸ¥æ‰¾
            file_path = os.path.join(excel_folder, file_path)

        if not os.path.exists(file_path):
            return f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}"

        if not file_path.lower().endswith(('.xlsx', '.xls', '.xlsm')):
            return "æ–‡ä»¶å¿…é¡»æ˜¯ Excel æ ¼å¼ (.xlsx, .xls, .xlsm)"

        return True

    def load_sku_data(self, excel_file, sheet_name, combined_sku_col, sku_col,
                     pcs_col, url_col, start_row, use_cache=True, cache_size=100,
                     label_format="Ã—{pcs}", output_mode="by_combined_sku",
                     filter_combined_sku=""):
        
        self._cache_max_size = cache_size
        self._cache_hits = 0
        self._cache_misses = 0
        
        try:
            print("\n" + "="*80)
            print("ğŸš€ å¼€å§‹åŠ è½½ Excel SKU æ•°æ®")
            print("="*80)
            print(f"ğŸ“Š ç¼“å­˜çŠ¶æ€: {'å¯ç”¨' if use_cache else 'ç¦ç”¨'}")
            print(f"ğŸ“¦ å½“å‰ç¼“å­˜: {len(self._image_cache)}/{self._cache_max_size} å¼ å›¾ç‰‡")
            print(f"ğŸ”„ è¾“å‡ºæ¨¡å¼: {output_mode}")

            # 1. ç¡®å®šExcelæ–‡ä»¶è·¯å¾„æˆ–URL
            excel_file = excel_file.strip()

            # æ£€æŸ¥æ˜¯å¦ä¸º URL
            if is_url(excel_file):
                print(f"\nğŸ“– ä»URLåŠ è½½Excelæ–‡ä»¶: {excel_file}")
                try:
                    headers = {
                        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
                    }
                    print(f"   ğŸŒ ä¸‹è½½ä¸­...")
                    response = requests.get(excel_file, headers=headers, timeout=60, verify=False)
                    response.raise_for_status()

                    # ä» BytesIO è¯»å– Excel
                    excel_data = BytesIO(response.content)
                    df = pd.read_excel(excel_data, sheet_name=sheet_name, header=None)
                    print(f"   âœ… æˆåŠŸä¸‹è½½å¹¶è¯»å– {len(df)} è¡Œæ•°æ®")

                except requests.exceptions.RequestException as e:
                    raise ConnectionError(
                        f"ä¸‹è½½Excelæ–‡ä»¶å¤±è´¥: {excel_file}\n\n"
                        f"é”™è¯¯: {str(e)}\n\n"
                        f"è¯·æ£€æŸ¥:\n"
                        f"1. URLæ˜¯å¦æ­£ç¡®\n"
                        f"2. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸\n"
                        f"3. æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”å¯è®¿é—®"
                    )
            else:
                # æœ¬åœ°æ–‡ä»¶è·¯å¾„
                # å¦‚æœ excel_file æ˜¯å®Œæ•´è·¯å¾„ï¼ˆåŒ…å«è·¯å¾„åˆ†éš”ç¬¦æˆ–ç›˜ç¬¦ï¼‰ï¼Œç›´æ¥ä½¿ç”¨
                # å¦åˆ™ä» excel_files æ–‡ä»¶å¤¹ä¸­æŸ¥æ‰¾
                if excel_file and ('\\' in excel_file or '/' in excel_file or ':' in excel_file):
                    # å®Œæ•´è·¯å¾„
                    file_path = excel_file
                    print(f"\nğŸ“– ä½¿ç”¨å®Œæ•´è·¯å¾„: {file_path}")
                else:
                    # æ–‡ä»¶åï¼Œä» excel_files æ–‡ä»¶å¤¹ä¸­æŸ¥æ‰¾
                    file_path = os.path.join(excel_folder, excel_file)
                    print(f"\nğŸ“– ä½¿ç”¨æ–‡ä»¶å: {excel_file}")
                    print(f"   å®Œæ•´è·¯å¾„: {file_path}")

                if not os.path.exists(file_path):
                    raise FileNotFoundError(
                        f"Excelæ–‡ä»¶ä¸å­˜åœ¨: {file_path}\n\n"
                        f"è¯·æ£€æŸ¥:\n"
                        f"1. æ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡®\n"
                        f"2. å¦‚æœæ˜¯æ–‡ä»¶åï¼Œç¡®ä¿æ–‡ä»¶åœ¨: {excel_folder}\n"
                        f"3. å¦‚æœæ˜¯å®Œæ•´è·¯å¾„ï¼Œç¡®ä¿è·¯å¾„æ­£ç¡®"
                    )

                df = pd.read_excel(file_path, sheet_name=sheet_name, header=None)
                print(f"   âœ… æˆåŠŸè¯»å– {len(df)} è¡Œæ•°æ®")
            
            # 2. è§£æSKUåˆ†ç»„
            print(f"\nğŸ” è§£æSKUåˆ†ç»„æ•°æ®...")
            groups = self.parse_sku_groups(
                df, combined_sku_col, sku_col, pcs_col, 
                url_col, start_row, filter_combined_sku
            )
            
            if not groups:
                print("âš ï¸ æœªæ‰¾åˆ°æœ‰æ•ˆçš„SKUåˆ†ç»„æ•°æ®")
                return self.create_empty_result()
            
            print(f"   âœ… æ‰¾åˆ° {len(groups)} ä¸ªç»„åˆSKU")
            
            # 3. æŒ‰è¾“å‡ºæ¨¡å¼å¤„ç†
            if output_mode == "by_combined_sku":
                return self.process_by_combined_sku(groups, use_cache, label_format)
            else:
                return self.process_all_in_one(groups, use_cache, label_format)
            
        except Exception as e:
            error_msg = f"åŠ è½½å¤±è´¥: {str(e)}"
            print(f"\nâŒ {error_msg}")
            import traceback
            traceback.print_exc()
            return self.create_empty_result(error_msg)
    
    def process_by_combined_sku(self, groups, use_cache, label_format):
        """æŒ‰ç»„åˆSKUåˆ†æ‰¹å¤„ç†ï¼ˆæ¨èæ¨¡å¼ï¼‰"""
        
        all_image_batches = []
        all_label_batches = []
        info_lines = []
        
        for idx, (combined_sku, group_data) in enumerate(groups.items(), 1):
            print(f"\n{'='*80}")
            print(f"ğŸ¯ [{idx}/{len(groups)}] å¤„ç†ç»„åˆSKU: {combined_sku}")
            print(f"{'='*80}")
            print(f"   å­SKUæ•°é‡: {len(group_data['items'])}")
            
            batch_images = []
            batch_labels = []
            
            # ===== ç¬¬ä¸€æ­¥ï¼šå…ˆæ”¶é›†æ‰€æœ‰å›¾ç‰‡ï¼Œæ‰¾å‡ºæœ€å¤§å°ºå¯¸ =====
            temp_images = []
            for item in group_data['items']:
                print(f"\n   ğŸ“¦ å¤„ç†SKU: {item['sku']}")
                print(f"      PCSæ•°: {item['pcs']}")
                print(f"      URL: {item['url'][:80]}...")
                
                img = self.download_image(item['url'], use_cache=use_cache)
                
                if img:
                    temp_images.append((img, item))
                    print(f"      âœ… åŠ è½½æˆåŠŸ ({img.size[0]}x{img.size[1]})")
                else:
                    print(f"      âŒ åŠ è½½å¤±è´¥")
            
            if not temp_images:
                info_lines.append(f"âŒ {combined_sku}: 0 ä¸ªSKU (å¤±è´¥)")
                print(f"\n   âŒ æ‰¹æ¬¡å¤±è´¥")
                continue
            
            # ===== ç¬¬äºŒæ­¥ï¼šæ‰¾å‡ºæœ€å¤§å°ºå¯¸ =====
            max_width = max(img.size[0] for img, _ in temp_images)
            max_height = max(img.size[1] for img, _ in temp_images)
            print(f"\n   ğŸ“ ç»Ÿä¸€å°ºå¯¸: {max_width}x{max_height}")
            
            # ===== ç¬¬ä¸‰æ­¥ï¼šè°ƒæ•´æ‰€æœ‰å›¾ç‰‡åˆ°ç»Ÿä¸€å°ºå¯¸ =====
            for img, item in temp_images:
                # è°ƒæ•´å›¾ç‰‡å°ºå¯¸
                img_resized = self.resize_and_pad(img, max_width, max_height)
                
                # è½¬æ¢ä¸ºnumpyæ•°ç»„
                img_array = np.array(img_resized).astype(np.float32) / 255.0
                if len(img_array.shape) == 2:  # ç°åº¦å›¾
                    img_array = np.stack([img_array] * 3, axis=-1)
                elif img_array.shape[-1] == 4:  # RGBA
                    img_array = img_array[:, :, :3]
                
                batch_images.append(img_array)
                
                # ç”Ÿæˆæ ‡ç­¾
                label = label_format.format(pcs=item['pcs'])
                batch_labels.append(label)
            
            # ===== ç¬¬å››æ­¥ï¼šå †å ä¸ºæ‰¹æ¬¡ =====
            batch_tensor = torch.from_numpy(np.stack(batch_images))
            all_image_batches.append(batch_tensor)
            
            labels_str = ",".join(batch_labels)
            all_label_batches.append(labels_str)
            
            info_lines.append(f"âœ… {combined_sku}: {len(batch_images)} ä¸ªSKU")
            print(f"\n   âœ… æ‰¹æ¬¡å®Œæˆ: {len(batch_images)} å¼ å›¾ç‰‡")
            print(f"      æ ‡ç­¾: {labels_str}")
        
        if not all_image_batches:
            print("\nâŒ æ²¡æœ‰æˆåŠŸåŠ è½½ä»»ä½•å›¾ç‰‡")
            return self.create_empty_result()
        
        # ç”ŸæˆæŠ¥å‘Š
        total_images = sum(len(batch) for batch in all_image_batches)
        info_str = "\n".join([
            "="*60,
            "ğŸ“Š Excel SKU åŠ è½½æŠ¥å‘Šï¼ˆæŒ‰ç»„åˆSKUåˆ†æ‰¹ï¼‰",
            "="*60,
            f"ç»„åˆSKUæ•°é‡: {len(groups)}",
            f"æ‰¹æ¬¡æ•°é‡: {len(all_image_batches)}",
            f"å›¾ç‰‡æ€»æ•°: {total_images}",
            "="*60,
            "",
            *info_lines,
            "",
            "="*60,
            f"ç¼“å­˜å‘½ä¸­: {self._cache_hits} æ¬¡",
            f"ç¼“å­˜æœªå‘½ä¸­: {self._cache_misses} æ¬¡",
            f"ç¼“å­˜å‘½ä¸­ç‡: {self._cache_hits/(self._cache_hits+self._cache_misses)*100:.1f}%" if (self._cache_hits+self._cache_misses) > 0 else "N/A",
            "="*60
        ])
        
        print("\n" + "="*80)
        print(f"ğŸ‰ åŠ è½½å®Œæˆ! å…± {len(all_image_batches)} ä¸ªæ‰¹æ¬¡ï¼Œ{total_images} å¼ å›¾ç‰‡")
        for i, labels in enumerate(all_label_batches):
            print(f"   æ‰¹æ¬¡{i+1}: {labels}")
        print("="*80 + "\n")
        
        return (all_image_batches, all_label_batches, info_str)

    def resize_and_pad(self, img, target_width, target_height):
        """
        è°ƒæ•´å›¾ç‰‡å°ºå¯¸å¹¶å±…ä¸­å¡«å……
        ä¿æŒå®½é«˜æ¯”ï¼Œä¸è¶³éƒ¨åˆ†ç”¨ç™½è‰²å¡«å……
        """
        # è®¡ç®—ç¼©æ”¾æ¯”ä¾‹
        width_ratio = target_width / img.size[0]
        height_ratio = target_height / img.size[1]
        scale_ratio = min(width_ratio, height_ratio)
        
        # è®¡ç®—æ–°å°ºå¯¸
        new_width = int(img.size[0] * scale_ratio)
        new_height = int(img.size[1] * scale_ratio)
        
        # ç¼©æ”¾å›¾ç‰‡
        img_resized = img.resize((new_width, new_height), Image.Resampling.LANCZOS)
        
        # åˆ›å»ºç™½è‰²èƒŒæ™¯
        result = Image.new('RGB', (target_width, target_height), (255, 255, 255))
        
        # è®¡ç®—å±…ä¸­ä½ç½®
        x = (target_width - new_width) // 2
        y = (target_height - new_height) // 2
        
        # ç²˜è´´å›¾ç‰‡
        result.paste(img_resized, (x, y))

        return result
    
    def process_all_in_one(self, groups, use_cache, label_format):
        """æ‰€æœ‰å›¾ç‰‡åˆå¹¶ä¸ºä¸€ä¸ªæ‰¹æ¬¡"""
        
        all_images = []
        all_labels = []
        info_lines = []
        
        for idx, (combined_sku, group_data) in enumerate(groups.items(), 1):
            print(f"\nğŸ¯ [{idx}/{len(groups)}] å¤„ç†ç»„åˆSKU: {combined_sku}")
            
            for item in group_data['items']:
                print(f"   ğŸ“¦ {item['sku']} (PCS:{item['pcs']})")
                
                img = self.download_image(item['url'], use_cache=use_cache)
                
                if img:
                    img_array = np.array(img).astype(np.float32) / 255.0
                    if len(img_array.shape) == 2:
                        img_array = np.stack([img_array] * 3, axis=-1)
                    elif img_array.shape[-1] == 4:
                        img_array = img_array[:, :, :3]
                    
                    all_images.append(img_array)
                    all_labels.append(label_format.format(pcs=item['pcs']))
            
            info_lines.append(f"{combined_sku}: {len(group_data['items'])} ä¸ªSKU")
        
        if not all_images:
            return self.create_empty_result()
        
        images_tensor = torch.from_numpy(np.stack(all_images))
        labels_str = ",".join(all_labels)
        
        info_str = "\n".join([
            "="*60,
            "ğŸ“Š Excel SKU åŠ è½½æŠ¥å‘Šï¼ˆå…¨éƒ¨åˆå¹¶ï¼‰",
            "="*60,
            f"ç»„åˆSKUæ•°é‡: {len(groups)}",
            f"å›¾ç‰‡æ€»æ•°: {len(all_images)}",
            "="*60,
            "",
            *info_lines,
            "",
            "="*60
        ])
        
        return ([images_tensor], [labels_str], info_str)
    
    def parse_sku_groups(self, df, combined_col, sku_col, pcs_col, url_col, 
                        start_row, filter_sku=""):
        """è§£æExcelæ•°æ®å¹¶æŒ‰ç»„åˆSKUåˆ†ç»„ï¼ˆæ”¯æŒç©ºå€¼ç»§æ‰¿ï¼‰"""
        groups = OrderedDict()  # ä½¿ç”¨æœ‰åºå­—å…¸ä¿æŒé¡ºåº
        
        col_map = {
            'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5,
            'G': 6, 'H': 7, 'I': 8, 'J': 9, 'K': 10, 'L': 11,
            'M': 12, 'N': 13, 'O': 14, 'P': 15, 'Q': 16, 'R': 17
        }
        
        combined_idx = col_map.get(combined_col.upper(), 0)
        sku_idx = col_map.get(sku_col.upper(), 1)
        pcs_idx = col_map.get(pcs_col.upper(), 2)
        url_idx = col_map.get(url_col.upper(), 3)
        
        parsed_count = 0
        skipped_count = 0
        current_combined_sku = None
        
        for idx in range(start_row - 1, len(df)):
            row = df.iloc[idx]
            
            # è¯»å–ç»„åˆSKUï¼ˆæ”¯æŒç©ºå€¼ç»§æ‰¿ä¸Šä¸€è¡Œï¼‰
            if combined_idx < len(row):
                combined_sku_value = row.iloc[combined_idx]
                
                if pd.isna(combined_sku_value) or str(combined_sku_value).strip() in ['', 'nan']:
                    if current_combined_sku:
                        combined_sku = current_combined_sku
                    else:
                        skipped_count += 1
                        continue
                else:
                    combined_sku = str(combined_sku_value).strip()
                    current_combined_sku = combined_sku
            else:
                skipped_count += 1
                continue
            
            # è¿‡æ»¤
            if filter_sku and filter_sku.strip() != "" and combined_sku != filter_sku.strip():
                skipped_count += 1
                continue
            
            # åˆå§‹åŒ–ç»„åˆSKU
            if combined_sku not in groups:
                groups[combined_sku] = {'items': []}
            
            # è¯»å–SKU
            sku = str(row.iloc[sku_idx]).strip() if sku_idx < len(row) else ""
            if not sku or sku == 'nan':
                skipped_count += 1
                continue
            
            # è¯»å–PCSæ•°
            try:
                pcs_value = row.iloc[pcs_idx] if pcs_idx < len(row) else 1
                pcs = int(pcs_value) if not pd.isna(pcs_value) else 1
                if pcs <= 0:
                    pcs = 1
            except (ValueError, TypeError):
                pcs = 1
            
            # è¯»å–URL
            url = str(row.iloc[url_idx]).strip() if url_idx < len(row) else ""
            if not url or url == 'nan' or not url.startswith('http'):
                print(f"      âš ï¸ è¡Œ{idx+1} è·³è¿‡æ— æ•ˆURL: {sku}")
                skipped_count += 1
                continue
            
            # æ·»åŠ åˆ°åˆ†ç»„
            groups[combined_sku]['items'].append({
                'sku': sku,
                'pcs': pcs,
                'url': url
            })
            parsed_count += 1
        
        print(f"   è§£ææˆåŠŸ: {parsed_count} æ¡")
        print(f"   è·³è¿‡: {skipped_count} æ¡")
        
        return groups
    
    def download_image(self, url, timeout=30, use_cache=True):
        """ä»URLä¸‹è½½å›¾ç‰‡ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
        
        if use_cache and url in self._image_cache:
            self._cache_hits += 1
            print(f"      ğŸ“¦ ä½¿ç”¨ç¼“å­˜")
            return self._image_cache[url].copy()
        
        self._cache_misses += 1
        
        try:
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
            
            print(f"      ğŸŒ ä¸‹è½½ä¸­...")
            response = requests.get(url, headers=headers, timeout=timeout, verify=False)
            response.raise_for_status()
            
            img = Image.open(BytesIO(response.content))
            img_rgb = img.convert('RGB')
            
            print(f"      âœ… ä¸‹è½½æˆåŠŸ ({img_rgb.size[0]}x{img_rgb.size[1]})")
            
            if use_cache:
                if len(self._image_cache) >= self._cache_max_size:
                    first_key = next(iter(self._image_cache))
                    del self._image_cache[first_key]
                
                self._image_cache[url] = img_rgb
            
            return img_rgb
            
        except Exception as e:
            print(f"      âŒ å¤±è´¥: {str(e)}")
        
        return None
    
    def create_empty_result(self, message="æ— æ•°æ®"):
        """åˆ›å»ºç©ºç»“æœ"""
        empty_img = np.zeros((512, 512, 3), dtype=np.float32)
        empty_tensor = torch.from_numpy(empty_img).unsqueeze(0)
        return ([empty_tensor], [""], f"âŒ {message}")


# èŠ‚ç‚¹æ˜ å°„
NODE_CLASS_MAPPINGS = {
    "ExcelSKULoader": ExcelSKULoader
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "ExcelSKULoader": "ğŸ“Š Excel SKUæ•°æ®åŠ è½½å™¨"
}